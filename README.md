# data-pipeline-airflow

## üìå Vis√£o Geral
Este projeto implementa um **pipeline de dados moderno** utilizando **Google Cloud Platform (GCP)**, com foco em ingest√£o, transforma√ß√£o e disponibiliza√ß√£o de dados para an√°lises de neg√≥cio.  

O pipeline integra dados de diferentes fontes (**Postgres CRM, Google Analytics 4, etc.**) e os disponibiliza de forma tratada e padronizada no **BigQuery**, seguindo as camadas:  
- **RAW** ‚Üí ingest√£o bruta dos dados.  
- **ETL** ‚Üí limpeza, padroniza√ß√£o e enriquecimento.  
- **DELIVERY** ‚Üí m√©tricas, vis√µes anal√≠ticas e dashboards.  

---

## ‚öôÔ∏è Principais Componentes

- **Cloud Functions (Gen2)**  
  Extrai dados do Postgres (CRM) em *chunks* ‚Üí grava Parquet no GCS ‚Üí carrega no BigQuery.  

- **Cloud Composer (Airflow)**  
  Orquestra o pipeline:  
  1. Executa a Cloud Function.  
  2. Move dados de GCS ‚Üí BigQuery RAW.  
  3. Executa queries de transforma√ß√£o (ETL).  
  4. Cria/atualiza views em Delivery.  

- **BigQuery**  
  - Dataset **RAW**: ingest√£o bruta.  
  - Dataset **ETL**: staging e padroniza√ß√£o.  
  - Dataset **DELIVERY**: vis√µes anal√≠ticas para dashboards.  

- **Data Catalog & Lineage**  
  Cat√°logo de metadados e rastreabilidade das tabelas e colunas.  

- **GitHub Actions (CI/CD)**  
  - Deploy autom√°tico da Cloud Function.  
  - Deploy autom√°tico das DAGs e SQLs do Composer.  
  - Vari√°veis sens√≠veis armazenadas em **GitHub Secrets**.  

---

## üìÇ Estrutura de Pastas


